

require(rARPACK)
require(Matrix)

######################################################
## subfunctions for adaptiveImpute                  ##
## subfunctions for fastAdi are given at the bottom ##
######################################################

sign.lm=function(M.p,lambda.hat,u.hat,v.hat,r,ind){
  nz=which(ind)
  X = matrix(0,sum(ind),r)
  for(i in 1:r){
    E = lambda.hat[i]*u.hat[,i] %*% t(v.hat[,i])
    X[,i] = E[nz]
  }
  y=M.p[nz]
  XX.inv = solve(crossprod(X))
  XTY = t(X) %*% y
  coef = XX.inv %*% XTY
  lambda.hat.R = diag(c(lambda.hat*coef))
  out = u.hat %*% lambda.hat.R %*% t(v.hat)
  return(out)}

sign.asympt=function(M.p,n,d,lambda.hat,u.hat,v.hat,r,ind){
  svd.Mp = svds(M.p,r)
  Vp.Vhat = crossprod(rep(1,d),(svd.Mp$v*v.hat))
  Up.Uhat = crossprod(rep(1,n),(svd.Mp$u*u.hat))
  coef = sign(Vp.Vhat * Up.Uhat)
  lambda.hat.R = diag(c(lambda.hat*coef))
  out = u.hat %*% (lambda.hat.R %*% t(v.hat))
  return(out)}

sign.greedy=function(M.p,lambda.hat,u.hat,v.hat,r,ind){
  nr = 2^r
  coef.set = matrix(0,nr,r)
  for(i in 1:r){#i=1
    motiv = c(rep(1,nr/(2^i)),rep(-1,nr/(2^i)))
    coef.set[,i] = rep(motiv,2^(i-1))
  }
  MSEs = c()
  for(j in 1:nr){#j=1
    coef = coef.set[j,]
    lambda.hat.R = diag(c(lambda.hat*coef))
    Mhat = u.hat %*% (lambda.hat.R %*% t(v.hat))
    diff = (M.p-Mhat)[ind]
    MSEs[j] = mean(diff^2)
  }
  pick = which.min(MSEs)
  coef = coef.set[pick,]
  lambda.hat.R = diag(c(lambda.hat*coef))
  out = u.hat %*% (lambda.hat.R %*% t(v.hat))
  return(out)}

Initial=function(M.p,r,p.hat,n,d,ind,sign.choice){
  SIG = (t(M.p)%*%M.p)/p.hat^2
  SIG.diag = (p.hat-1)*diag(SIG)
  diag(SIG) = diag(SIG) + SIG.diag
  SIG2 = (M.p%*%t(M.p))/p.hat^2
  SIG2.diag = (p.hat-1)*diag(SIG2)
  diag(SIG2) = diag(SIG2) + SIG2.diag
  
  obj=svds(SIG,r)
  obj2=svds(SIG2,r)
  
  tau = (sum(diag(SIG))-sum(obj$d))/(d-r)
  lambda.hat=sqrt(obj$d-tau)
  v.hat=obj$v
  u.hat=obj2$v
  
  if(sign.choice=="asympt"){
    M.hat=sign.asympt(M.p,n,d,lambda.hat,u.hat,v.hat,r,ind)
  }else{
    if(sign.choice=="greedy"){
      M.hat=sign.greedy(M.p,lambda.hat,u.hat,v.hat,r,ind)
    }else{
      M.hat=sign.lm(M.p,lambda.hat,u.hat,v.hat,r,ind)
    }
  }
  return(M.hat)}

SVD.F=function(M,r,M.p,d){
  obj=svds(M,r)
  M2 = M^2
  MTM = colSums(M2)
  tau = (sum(MTM) - sum(obj$d^2))/(d-r)
  lambda.hat=sqrt(obj$d^2 - tau)
  v.hat=obj$v
  u.hat=obj$u 
  M.hat= u.hat %*% (diag(lambda.hat)%*% t(v.hat)) 
  return(M.hat)}

#####################
## Adaptive-Impute ##
#####################

adi = function(M.p,r=NULL, fast = T, sparse=c(TRUE,FALSE),
                       sign.choice = c("asympt","lm","greedy"),
                       min.value=NULL,max.value=NULL,
                       tol=1e-07,itmax=200){
  
  n = nrow(M.p); d = ncol(M.p)
  if(is.null(r)){
    r.temp = round(min(n,d)/10)
    sval = svds(M.p,94,nu=0,nv=0)$d
    sval.ratio = (sval[1:(r.temp-1)]-sval[2:r.temp])/sval[1:(r.temp-1)]
    r = which.max(sval.ratio[-1])+1
  } 
  if(fast) return(fastAdi(M.p,r,tol, itmax))
  
  ind = !(M.p==0)
  p.hat = mean(ind)
  temp.M=Initial(M.p, r, p.hat,n,d,ind,sign.choice)
  if(sparse==TRUE|p.hat<0.5){
    M.p = Matrix(M.p, sparse = TRUE)
    ifelse(is.null(max.value), max.value<-max(M.p@x), temp.M[temp.M>max.value]<-max.value)
    ifelse(is.null(min.value), min.value<-min(M.p@x), temp.M[temp.M<min.value]<-min.value)
  }else{
    ifelse(is.null(max.value), max.value<-max(M.p[ind]), temp.M[temp.M>max.value]<-max.value)
    ifelse(is.null(min.value), min.value<-min(M.p[ind]), temp.M[temp.M<min.value]<-min.value)
  }
  
  itr=0; error=Inf
  while(error>tol){
    M = temp.M*(1-ind)+M.p
    temp=SVD.F(M,r, M.p,d) 
    temp.M1=temp
    error=sum((temp.M1-temp.M)^2)/sum(temp.M^2)	
    temp.M=temp.M1
    temp.M[temp.M>max.value]=max.value
    temp.M[temp.M<min.value] = min.value
    itr=itr+1
    if(itr%%10==0)cat(".")
    if(itr>itmax){break}
  }
  return(temp.M)
}






#####################################
## subfunctions for fastAdi        ##
#####################################


##############################
#  eigInit and its subfunction Mx
#  are to make the svd in the initalizer.
#  given sparse M compute eigen of 
#  t(M)%*%M/p^2 - (1-p)*diag(t(M)%*%M)
#  where p is the mean nnz of M.
##############################

eigInit = function(M, r){
  #  given sparse M compute eigen of 
  #  t(M)%*%M - (1-p)*diag(t(M)%*%M)
  #  where p is the mean nnz of M.
  
  return(
    eigs_sym(
      Mx, r, n = ncol(M), 
      args = list(M=M, 
                  p = nnzero(M)/prod(dim(M))
      )
    )
  )
  
}                


Mx = function(x, args)
{
  ## Has the effect of  [ t(M)%*%M - (1-p)*diag(t(M)%*%M) ] *x
  return(drop(crossprod(args$M, args$M%*%x)/args$p^2 - (1-args$p)*Diagonal(ncol(args$M),colSums(args$M^2))%*%x/args$p^2))
}


##############################
# svdSUV and its subfunctions Ax and Atx
# are source files for taking the svd of 
# M = S + U%*%V^T
# where S is sparse with nonzeros that match the Data, it is the residuals:
# S = Data - U%*%V^T  (where Data is sparse and this operation is only on the nonzeros)
# Thank you to Yixuan Qiu for help.  


svdSUV = function(U,V, Data){
  # main function
  #  U and V are skinny matrices, probably the parameters.
  # Data is a sparse data matrix.
  # returns svd of 
  # M = S + U%*%V^T
  # where S is sparse with nonzeros that match the Data
  # S = Data - U%*%V^T  (where Data is sparse and this operation is only on the nonzeros)
  
  S = graphMult(U, V, Data, resid = T)
  args = list(S = S, U=U, V=V)
  ei = eigs_sym(f, ncol(args$U), n = ncol(args$S), args = args)
  u = as.matrix(Ax(ei$vec, args))
  u = apply(u,2,function(x) return(x/sqrt(sum(x^2))))
  return(list(u =u , v = ei$vec, d = sqrt(ei$val)))
  
}


Ax = function(x, args)
{
  ## Has the effect of A * x,
  return(drop(args$S %*% x + args$U%*%crossprod(args$V,x)))
}

Atx = function(x, args)
{
  ## Has the effect of A' * x, 
  return(drop(t(args$S) %*% x + args$V%*%crossprod(args$U,x)))
}

f = function(x, args)
{
  Atx(Ax(x, args), args)
}


########################
# graphMult is a subfunction in several pieces for computing the residuals
# S = G - U%*%t(V)
# but only computing it on the nonzero elements of G.
########################

graphMult = function(U,V,G, resids = F){
  # U and V are matrices with U %*% V^T defined.
  # G is a sparse matrix 
  # if resids = F, this function computes the elements of U%*%V^T on *only* non-zero elements of G.
  # if resids = T, this function computes the elements of G - U%*%V^T on *only* non-zero elements of G.
  
  mt = as(G, "dgTMatrix")
  # the indices for which we want to compute the matrix multiplication:
  i = mt@i+1
  j = mt@j+1
  
  # the rows of U and the columns of V for which we want to compute the multiplication:
  left= U[i,]
  right =  V[j,]  #  Note:  there is most certainly a more memory efficient way to do this.
  
  # the inner products to compute the elements of the U%*%V:
  uv = rowSums(left*right)
  
  if(!resids) return(sparseMatrix(i=i, j=j, x = uv))
  if(resids) return(sparseMatrix(i=i, j=j, x = mt@x - uv))
  
}



#######################################
# The initializer currently uses a different "sign" matching function,
#  which is faster. 
# If the old matching functions need to be adapted, then
# they functions need to be adapted to take an svds and return an svds.
#   Also, they cannot use the (dense) ind matrix.
#######################################



positive = function(x){
  x[x<0] = .001
  return(x)
}


fastInitial=function(M.p,r){
  ei = eigInit(M.p, r)
  
  p = nnzero(M.p)/prod(dim(M.p))
  tau = (sum(M.p@x^2)/p-sum(ei$val))/(ncol(M.p)-r)
  s = list(u=c(),d= c(),v=c())                                  
  s$d=sqrt(positive(ei$val-tau))
  s$v=ei$vectors
  s$u=eigInit(t(M.p), r)$vec
  
  B = svd(t(s$u)%*%(M.p%*%s$v))
  s$u = s$u %*%B$u
  s$v = s$v %*% B$v
  return(s)
  return(M.hat)}


#####################
# threshSVD is the key internal function for fastAdi
#####################

threshSVD= function(so, M.p, frobMp){
  
  # uses sparse+lowrank svd
  # computes thresholding parameters
  # returns the thresholded SVD 
  # M.p is the data
  # frobMp only needs to be computed once. 
  # It is the squared frobeinus norm of M.p (frobMp = sum(M.p@x^2))
  d = ncol(M.p)
  s = svdSUV(so$u, so$v%*%diag(so$d), M.p)
  MTM = frobMp + sum(so$d^2) - sum(graphMult(so$u,so$v%*%diag(so$d),M.p)@x^2)  
  tau = (sum(MTM) - sum(s$d^2))/(d-r)  
  s$d=sqrt(positive(s$d^2 - tau))
  return(s)}

#####################
## fastAdi ##
#####################

fastAdi = function(M.p,r,tol=1e-07,itmax=200){
  
  n = nrow(M.p); d = ncol(M.p)
  M.p = as(M.p, "dgCMatrix")
  p.hat = nnzero(M.p)/prod(dim(M.p))
  s = fastInitial(M.p, r)
  
  frobMp = sum(M.p@x^2)
  itr=0; error=Inf
  oldResids = M.p@x
  resids = graphMult(s$u,s$v%*%diag(s$d),M.p, resids = T)@x
  
  while(error> tol){
    oldResids = resids
    s=threshSVD(s,M.p,frobMp) 
    resids = graphMult(s$u,s$v%*%diag(s$d),M.p, resids = T)@x
    print(sd(resids))
    error=sum((oldResids-resids)^2)/sum(resids^2)
    
    itr=itr+1
    if(itr%%10==0)cat(".")
    if(itr>itmax){break}
  }
  return(s)
}